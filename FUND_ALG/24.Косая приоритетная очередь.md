Приоритетные очереди. Косая приоритетная очередь, её реализация на базе структуры данных вида бинарное дерево. Операции вставки элемента, поиска минимума/максимума, удаления минимума/максимума, слияния с разрушением и без разрушения исходных косых приоритетных очередей; их вычислительные сложности и реализация на языке C.

Косая куча (Skew Heap) — это элегантная и простая структура данных, которая является **саморегулирующимся** аналогом левосторонней кучи.

Если левосторонняя куча тратит память и силы на поддержание специального баланса (хранит `npl` и проверяет длину путей), то косая куча действует по принципу: **«Делай обмен детей при каждом слиянии, и в среднем всё будет хорошо»**.

---

### 1. Структура данных

Косая куча — это бинарное дерево, где выполняется свойство кучи (родитель меньше или равен детям для Min-Heap).

В структуре узла нет никаких дополнительных полей (ни баланса, ни высоты, ни npl).

C

```
typedef struct Node {
    int key;
    struct Node *left;
    struct Node *right;
} Node;
```

---

### 2. Главная операция: Слияние (Merge)

Вся магия косой кучи заключена в операции слияния. Вставка и удаление — это просто частные случаи слияния.

#### Логика алгоритма (Слияние с разрушением)

Пусть у нас есть две кучи $H_1$ и $H_2$. Мы хотим слить их в одну.

1. **База рекурсии:** Если одна из куч пуста, возвращаем другую.
    
2. **Упорядочивание:** Сравниваем корни. Пусть корень $H_1$ меньше корня $H_2$. Если нет — меняем местами $H_1$ и $H_2$, чтобы $H_1$ всегда была с меньшим корнем.
    
3. **Рекурсия:** Сливаем **правую** ветвь $H_1$ с кучей $H_2$.
    
4. **Косой обмен (The Skew):** У $H_1$ (результирующего корня) **меняем местами левого и правого сына**.
    

Именно этот безусловный обмен на каждом шаге рекурсии гарантирует, что дерево не выродится в длинную ветку надолго. «Тяжелые» ветки постоянно перебрасываются влево.

---

### 3. Остальные операции

Все они реализуются через Merge.

- **Вставка (Insert):** Создать узел из нового элемента и слить (`Merge`) его с основным деревом.
    
- **Поиск минимума (Find Min):** Просто вернуть значение корня (оно минимально по свойству кучи).
    
- **Удаление минимума (Delete Min):**
    
    1. Запоминаем корень.
        
    2. У корня есть два поддерева: левое и правое.
        
    3. Делаем `Merge(left, right)`. Это и будет новая куча.
        
    4. Старый корень удаляем.
        

---

### 4. Реализация на языке C

Ниже представлена реализация основных операций, включая слияние с разрушением.

C

```
#include <stdio.h>
#include <stdlib.h>

typedef struct Node {
    int key;
    struct Node *left;
    struct Node *right;
} Node;

// Создание узла
Node* createNode(int key) {
    Node* n = (Node*)malloc(sizeof(Node));
    n->key = key;
    n->left = n->right = NULL;
    return n;
}

// === ОПЕРАЦИЯ СЛИЯНИЯ (Destructive Merge) ===
// Это сердце алгоритма
Node* merge(Node* h1, Node* h2) {
    // 1. Базовые случаи
    if (!h1) return h2;
    if (!h2) return h1;

    // 2. Гарантируем, что h1 имеет меньший ключ (для Min-Heap)
    if (h1->key > h2->key) {
        Node* temp = h1;
        h1 = h2;
        h2 = temp;
    }

    // 3. Рекурсивно сливаем правую ветвь h1 с h2
    // И сразу перекидываем результат в ЛЕВУЮ ветку (Swap)
    // Классическая реализация: merge right, then swap.
    // Эквивалентно: temp = left; left = merge(right, h2); right = temp;
    
    Node* temp = h1->left;
    h1->left = merge(h1->right, h2);
    h1->right = temp;

    return h1;
}

// === ВСТАВКА ===
Node* insert(Node* root, int key) {
    Node* newNode = createNode(key);
    return merge(root, newNode);
}

// === УДАЛЕНИЕ МИНИМУМА ===
Node* deleteMin(Node* root) {
    if (!root) return NULL;

    Node* leftChild = root->left;
    Node* rightChild = root->right;

    free(root); // Удаляем старый корень

    // Сливаем детей, чтобы получить новое дерево
    return merge(leftChild, rightChild);
}

// Очистка памяти (рекурсивно)
void freeHeap(Node* root) {
    if (!root) return;
    freeHeap(root->left);
    freeHeap(root->right);
    free(root);
}

int main() {
    Node* heap = NULL;
    
    // Тест вставки
    heap = insert(heap, 10);
    heap = insert(heap, 5);
    heap = insert(heap, 20);
    heap = insert(heap, 3); // 3 станет новым корнем

    printf("Min element: %d\n", heap->key); // Должно быть 3

    // Тест удаления
    heap = deleteMin(heap);
    printf("New min after delete: %d\n", heap->key); // Должно быть 5

    freeHeap(heap);
    return 0;
}
```

---

### 5. Слияние с разрушением vs Без разрушения

В билете требуется пояснить разницу.

1. **Слияние с разрушением (Destructive):**
    
    - Именно то, что реализовано выше.
        
    - Мы меняем указатели `left` и `right` у существующих узлов.
        
    - Исходные кучи $H_1$ и $H_2$ перестают существовать как независимые объекты (они смешиваются).
        
    - **Плюсы:** Быстро, не требует дополнительной памяти.
        
2. **Слияние без разрушения (Non-destructive / Persistent):**
    
    - Требуется, если нам нужно сохранить исходные версии куч $H_1$ и $H_2$ для истории или параллельных процессов.
        
    - **Алгоритм:** Перед тем как что-то менять в узле при спуске рекурсии, мы должны создать **копию** этого узла.
        
    - Мы будем копировать все узлы вдоль "пути слияния".
        
    - **Сложность:** В худшем случае $O(N)$, так как придется копировать много узлов. В функциональном программировании это стандарт, но в Си используется редко из-за накладных расходов.
        

---

### 6. Вычислительная сложность (Амортизированная!)

Это самый важный теоретический момент билета.

У косой кучи **нет** гарантии, что высота дерева будет логарифмической в худшем случае. Дерево может выродиться в линию (как связный список).

- **Худший случай (одной операции):** $O(n)$.
    
- **Амортизированная сложность:** $O(\log n)$.
    

Что это значит:

Если мы сделаем последовательность из $M$ операций, то суммарное время будет $O(M \log n)$. Какая-то одна операция может быть долгой ($O(n)$), но она так перестроит дерево (благодаря обменам), что следующие операции будут очень быстрыми.

|**Операция**|**Амортизированная сложность**|**Худший случай (Worst Case)**|
|---|---|---|
|**Merge**|$O(\log n)$|$O(n)$|
|**Insert**|$O(\log n)$|$O(n)$|
|**Delete Min**|$O(\log n)$|$O(n)$|
|**Find Min**|$O(1)$|$O(1)$|

### Главные отличия от Левосторонней кучи (Leftist Heap):

1. **Память:** Косая куча не хранит `npl` (экономия 4 байт на узел).
    
2. **Логика:** Левосторонняя делает обмен _условно_ (только если нарушен баланс), Косая — _всегда_ (безусловно).
    
3. **Сложность:** Левосторонняя гарантирует $O(\log n)$ всегда. Косая гарантирует $O(\log n)$ только в среднем (амортизированно).
    

Если спросят на экзамене: "Почему мы используем косые кучи, если левосторонние стабильнее?"

Ответ: Косые кучи проще в реализации (не нужно считать npl) и на практике часто работают быстрее за счет отсутствия проверок условий и лучшей работы с кэшем процессора (локальность данных меняется динамически).